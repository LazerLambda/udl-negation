experiment: MLMExperiment
name: Neg Only Experiment
seed: 42
data_collator: DataCollatorForLanguageModeling
model:
  name: prajjwal1/bert-small
  freeze_lower: 0
  freeze_upper: 3
  target_path: ./models/
  tmp_path: ./models/
training:
  epochs: 3
  batch_size: 16
  lr: 5e-5
  eval_steps_n: 2
  eval_steps: True
data:
  path: ./data/processed/roberta_filtered/debug_large.txt # ./data/processed/data.txt
  test-prop: 0.05
  blocksize: 128
