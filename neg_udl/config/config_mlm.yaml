experiment: MLMExperiment
name: Neg Only Experiment - LARGE
seed: 42
data_collator: DataCollatorForLanguageModeling
model:
  name: roberta-large
  freeze_lower: 0
  freeze_upper: 16
  target_path: ./models/
  tmp_path: ./models/
training:
  epochs: 5
  batch_size: 16
  lr: 5e-5
  eval_steps_n: 10
  eval_steps: True
data:
  path: './data/processed/data.txt'
  test-prop: 0.05
  blocksize: 128
